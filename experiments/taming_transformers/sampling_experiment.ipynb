{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experimentos muestreando imágenes sintéticas desde modelos previamente entrenados\n",
    "\n",
    "Cambiamos el directorio de trabajo en el clúster GPU y nos situamos en el directorio del modelo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/homeGPU1/pbedmar/pycharm/experiments/taming_transformers/taming-transformers\n"
     ]
    }
   ],
   "source": [
    "%cd \"/mnt/homeGPU1/pbedmar/pycharm/experiments/taming_transformers/taming-transformers/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from functions import *\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carga de modelos\n",
    "Todos los modelos de esta sección han sido entrenados con imágenes de tamaño 256x256, buscando un equilibrio entre eficiencia e imágenes con un tamaño razonable"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modelos entrenados sobre ejemplos positivos de tamaño 256x256, sin data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    }
   ],
   "source": [
    "models_256 = []\n",
    "titles_256 = [\"Input\", \"VQGAN 256x256 - 70ep\", \"VQGAN 256x256 - 90ep\", \"VQGAN 256x256 - 110ep\", \"VQGAN 256x256 - 130ep\", \"VQGAN 256x256 - 150ep\", \"VQGAN 256x256 - 170ep\"]\n",
    "\n",
    "config_name = \"_fixseed_256_\"\n",
    "\n",
    "directory = \"2022-06-09T13-18-53\"\n",
    "config_name_ep = config_name+\"70/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256.append(model)\n",
    "\n",
    "directory = \"2022-06-09T13-52-36\"\n",
    "config_name_ep = config_name+\"90/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256.append(model)\n",
    "\n",
    "directory = \"2022-06-09T14-36-21\"\n",
    "config_name_ep = config_name+\"110/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256.append(model)\n",
    "\n",
    "directory = \"2022-06-09T15-29-57\"\n",
    "config_name_ep = config_name+\"130/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256.append(model)\n",
    "\n",
    "directory = \"2022-06-09T16-41-01\"\n",
    "config_name_ep = config_name+\"150/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256.append(model)\n",
    "\n",
    "directory = \"2022-06-09T18-01-50\"\n",
    "config_name_ep = config_name+\"170/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256.append(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modelos entrenados sobre ejemplos positivos de tamaño 256x256, con la secuencia data augmentation 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    }
   ],
   "source": [
    "models_256_aug = []\n",
    "titles_256_aug = [\"Input\", \"VQGAN 256x256 aug - 70ep\", \"VQGAN 256x256 aug - 90ep\", \"VQGAN 256x256 aug - 110ep\", \"VQGAN 256x256 aug - 130ep\", \"VQGAN 256x256 aug - 150ep\", \"VQGAN 256x256 aug - 170ep\"]\n",
    "\n",
    "config_name = \"_fixseed_256_aug_\"\n",
    "\n",
    "directory = \"2022-06-09T19-35-17\"\n",
    "config_name_ep = config_name+\"70/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug.append(model)\n",
    "\n",
    "directory = \"2022-06-09T21-05-22\"\n",
    "config_name_ep = config_name+\"90/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug.append(model)\n",
    "\n",
    "directory = \"2022-06-09T23-01-37\"\n",
    "config_name_ep = config_name+\"110/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug.append(model)\n",
    "\n",
    "directory = \"2022-06-10T01-26-18\"\n",
    "config_name_ep = config_name+\"130/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug.append(model)\n",
    "\n",
    "directory = \"2022-06-10T04-19-44\"\n",
    "config_name_ep = config_name+\"150/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug.append(model)\n",
    "\n",
    "directory = \"2022-06-10T07-42-18\"\n",
    "config_name_ep = config_name+\"170/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug.append(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modelos entrenados sobre ejemplos positivos de tamaño 256x256, con la secuencia data augmentation 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    }
   ],
   "source": [
    "models_256_aug_2 = []\n",
    "titles_256_aug_2 = [\"Input\", \"VQGAN 256x256 aug2 - 70ep\", \"VQGAN 256x256 aug2 - 90ep\", \"VQGAN 256x256 aug2 - 110ep\", \"VQGAN 256x256 aug2 - 130ep\", \"VQGAN 256x256 aug2 - 150ep\", \"VQGAN 256x256 aug2 - 170ep\"]\n",
    "\n",
    "config_name = \"_fixseed_256_aug2_\"\n",
    "\n",
    "directory = \"2022-06-10T11-39-28\"\n",
    "config_name_ep = config_name+\"70/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_2.append(model)\n",
    "\n",
    "directory = \"2022-06-10T13-12-13\"\n",
    "config_name_ep = config_name+\"90/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_2.append(model)\n",
    "\n",
    "directory = \"2022-06-10T15-11-51\"\n",
    "config_name_ep = config_name+\"110/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_2.append(model)\n",
    "\n",
    "directory = \"2022-06-10T17-41-02\"\n",
    "config_name_ep = config_name+\"130/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_2.append(model)\n",
    "\n",
    "directory = \"2022-06-10T20-41-56\"\n",
    "config_name_ep = config_name+\"150/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_2.append(model)\n",
    "\n",
    "directory = \"2022-06-11T00-12-39\"\n",
    "config_name_ep = config_name+\"170/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_2.append(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modelos entrenados sobre ejemplos positivos de tamaño 256x256, con la secuencia data augmentation 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    }
   ],
   "source": [
    "models_256_aug_3 = []\n",
    "titles_256_aug_3 = [\"Input\", \"VQGAN 256x256 aug3 - 70ep\", \"VQGAN 256x256 aug3 - 90ep\", \"VQGAN 256x256 aug3 - 110ep\", \"VQGAN 256x256 aug3 - 130ep\", \"VQGAN 256x256 aug3 - 150ep\", \"VQGAN 256x256 aug3 - 170ep\"]\n",
    "\n",
    "config_name = \"_fixseed_256_aug3_\"\n",
    "\n",
    "directory = \"2022-06-11T04-16-48\"\n",
    "config_name_ep = config_name+\"70/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_3.append(model)\n",
    "\n",
    "directory = \"2022-06-11T05-50-56\"\n",
    "config_name_ep = config_name+\"90/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_3.append(model)\n",
    "\n",
    "directory = \"2022-06-11T07-52-04\"\n",
    "config_name_ep = config_name+\"110/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_3.append(model)\n",
    "\n",
    "directory = \"2022-06-11T10-22-33\"\n",
    "config_name_ep = config_name+\"130/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_3.append(model)\n",
    "\n",
    "directory = \"2022-06-11T13-23-48\"\n",
    "config_name_ep = config_name+\"150/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_3.append(model)\n",
    "\n",
    "directory = \"2022-06-11T16-54-41\"\n",
    "config_name_ep = config_name+\"170/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_3.append(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modelos entrenados sobre ejemplos positivos de tamaño 256x256, con la secuencia data augmentation 2, ahora entre 70 y 90 épocas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    }
   ],
   "source": [
    "models_256_aug_2_extraepochs = []\n",
    "titles_256_aug_2_extraepochs = [\"Input\", \"VQGAN 256x256 aug2 - 70ep\", \"VQGAN 256x256 aug2 - 75ep\", \"VQGAN 256x256 aug2 - 80ep\", \"VQGAN 256x256 aug2 - 85ep\", \"VQGAN 256x256 aug2 - 90ep\"]\n",
    "\n",
    "config_name = \"_fixseed_256_aug2_\"\n",
    "\n",
    "directory = \"2022-06-18T10-44-35\"\n",
    "config_name_ep = config_name+\"70/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_2_extraepochs.append(model)\n",
    "\n",
    "directory = \"2022-06-18T15-30-37\"\n",
    "config_name_ep = config_name+\"75/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_2_extraepochs.append(model)\n",
    "\n",
    "directory = \"2022-06-18T20-35-09\"\n",
    "config_name_ep = config_name+\"80/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_2_extraepochs.append(model)\n",
    "\n",
    "directory = \"2022-06-19T01-48-45\"\n",
    "config_name_ep = config_name+\"85/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_2_extraepochs.append(model)\n",
    "\n",
    "directory = \"2022-06-19T07-18-22\"\n",
    "config_name_ep = config_name+\"90/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_256_aug_2_extraepochs.append(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modelos entrenados sobre ejemplos negativos de tamaño 256x256, sin data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    }
   ],
   "source": [
    "models_negative256 = []\n",
    "titles_negative256 = [\"Input\", \"VQGAN 256x256 negative - 70ep\", \"VQGAN 256x256 negative - 90ep\", \"VQGAN 256x256 negative - 110ep\", \"VQGAN 256x256 negative - 130ep\", \"VQGAN 256x256 negative - 150ep\", \"VQGAN 256x256 negative - 170ep\"]\n",
    "\n",
    "config_name = \"_fixseed_negative256_\"\n",
    "\n",
    "directory = \"2022-06-20T16-21-00\"\n",
    "config_name_ep = config_name+\"70/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_negative256.append(model)\n",
    "\n",
    "directory = \"2022-06-20T21-50-22\"\n",
    "config_name_ep = config_name+\"90/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_negative256.append(model)\n",
    "\n",
    "directory = \"2022-06-21T05-18-21\"\n",
    "config_name_ep = config_name+\"110/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_negative256.append(model)\n",
    "\n",
    "directory = \"2022-06-21T14-24-52\"\n",
    "config_name_ep = config_name+\"130/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_negative256.append(model)\n",
    "\n",
    "directory = \"2022-06-22T01-01-04\"\n",
    "config_name_ep = config_name+\"150/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_negative256.append(model)\n",
    "\n",
    "directory = \"2022-06-22T13-24-59\"\n",
    "config_name_ep = config_name+\"170/\"\n",
    "config = load_config(\"logs/\"+directory+config_name_ep+\"configs/\"+directory+\"-project.yaml\", display=False)\n",
    "model = load_vqgan(config, ckpt_path=\"logs/\"+directory+config_name_ep+\"/checkpoints/last.ckpt\").to(DEVICE)\n",
    "models_negative256.append(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Obtención de muestras de los modelos\n",
    "El modelo necesita una entrada para poder producir una imagen sintética como salida. Probamos diferentes tipos de entrada (ruido uniforme, perlín, ...) para ver los resultados."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "validation_data = []\n",
    "\n",
    "validation_data.append(\n",
    "    ('https://assets.fishersci.com/TFS-Assets/CCG/Chemical-Structures/chemical-structure-cas-67-64-1.jpg-650.jpg', 0))\n",
    "validation_data.append(('https://i.pinimg.com/736x/3f/26/21/3f2621fa39b9ed4706ba1edba07d61c5.jpg', 0))\n",
    "validation_data.append((torch.rand(1, 3, 256, 256), 2))\n",
    "validation_data.append((torch.rand(1, 3, 256, 256), 2))\n",
    "validation_data.append((\n",
    "                       \"https://img.myloview.es/posters/checkered-chequered-squares-pattern-and-background-chessboard-chess-checkerboard-texture-pattern-simple-and-basic-monochrome-pepita-alternating-squares-backdrop-400-225411586.jpg\",\n",
    "                       0))\n",
    "validation_data.append((\"../../../datasets/sample/perlin_python_1_1.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/perlin_python_1_2.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/perlin_python_1_4.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/perlin_python_3_1.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/perlin_python_3_2.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/perlin_python_3_4.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/perlin_python_5_1.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/perlin_python_5_2.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/perlin_python_5_4.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/perlin_python_7_1.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/perlin_python_7_2.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/perlin_python_7_4.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/turbulence.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/30.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/31.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/32.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/33.jpg\", 1))\n",
    "validation_data.append((\"../../../datasets/sample/34.jpg\", 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Resultados con el modelo 256x256 sin data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "path = \"../validation/256/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "img = reconstruction_pipeline(models_256, validation_data, titles_256, size=256)\n",
    "img.save(path+\"256.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "path = \"../validation/256/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "img = reconstruction_pipeline(models_256_aug, validation_data, titles_256_aug, size=256)\n",
    "img.save(path+\"aug.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "path = \"../validation/256/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "img = reconstruction_pipeline(models_256_aug_2, validation_data, titles_256_aug_2, size=256)\n",
    "img.save(path+\"aug2.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "path = \"../validation/256/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "img = reconstruction_pipeline(models_256_aug_3, validation_data, titles_256_aug_3, size=256)\n",
    "img.save(path+\"aug3.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "path = \"../validation/256/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "img = reconstruction_pipeline(models_256_aug_2_extraepochs, validation_data, titles_256_aug_2_extraepochs, size=256)\n",
    "img.save(path+\"aug2_extraepochs.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "Unsqueezed: torch.Size([1, 3, 256, 256])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n",
      "VQGAN --- VQModel: latent shape: torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "path = \"../validation/negative256/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "img = reconstruction_pipeline(models_negative256, validation_data, titles_negative256, size=256)\n",
    "img.save(path+\"negative256.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}